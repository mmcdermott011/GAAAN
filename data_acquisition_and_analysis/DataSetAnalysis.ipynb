{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALBUM ART GAN WORKBOOK**\n",
    "*by Michael McDermott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import os.path\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size of dataframe (64064, 8)\n",
      "Size of dataframe after dropping duplicates (53097, 8)\n",
      "Unnamed: 0       False\n",
      "album_id         False\n",
      "link_to_image    False\n",
      "album_name       False\n",
      "artist_name      False\n",
      "artist_id        False\n",
      "genre            False\n",
      "year             False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"masterAlbumList.csv\")\n",
    "col_names = ['album_id', 'link_to_image', 'album_name', 'artist_name', 'artist_id', 'genre', 'year']\n",
    "\n",
    "#first 58 lines were unnecessary appendages of the column legend\n",
    "#df = df.drop(df.index[:58])\n",
    "\n",
    "#see original size of dataframe\n",
    "print(\"Original Size of dataframe\",df.shape)\n",
    "\n",
    "#csv list only eliminated duplicates based off of album id, but not based off album name\n",
    "#ive found some artists have the same album uploaded more than once on their page, but the album has different ids\n",
    "#we need to get rid of duplicates based on the album name and artist\n",
    "b = df.drop_duplicates(subset=['album_name', 'artist_name'], keep=\"first\")\n",
    "\n",
    "#lets see how many there are now,\n",
    "print(\"Size of dataframe after dropping duplicates\",b.shape)\n",
    "#check if there are any null or NaN values \n",
    "print(b.isnull().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Number of unique artists:  7345\n",
      "Number of unique genres:  525\n",
      "['alternative emo' 'anthem emo' 'swancore' 'unknown' 'albany ny indie'\n",
      " 'euphoric hardstyle' 'metallic hardcore' 'dreamo' 'emo' 'pop punk'\n",
      " 'neon pop punk' 'easycore' 'tulsa indie' 'baroque pop' 'dance pop'\n",
      " 'modern rock' 'ann arbor indie' 'indie pop' 'chiptune' 'otacore'\n",
      " 'canadian post-hardcore' 'dayton indie' 'melodic metalcore' 'metalcore'\n",
      " 'christian alternative rock' 'christian punk' 'horror punk'\n",
      " 'brooklyn indie' 'dance-punk' 'lawrence ks indie' 'alternative rock'\n",
      " 'dc hardcore' 'post-hardcore' 'mathcore' 'progressive post-hardcore'\n",
      " 'alternative metal' 'charlotte nc indie' 'american metalcore'\n",
      " 'el paso indie' 'lexington ky indie' 'christian metal' 'deathstep'\n",
      " 'christian rock' 'electropowerpop' 'chamber pop' 'christian hardcore'\n",
      " 'chaotic hardcore' 'alabama metal' 'art pop' 'ambient folk' 'indie folk'\n",
      " 'australian indie' 'indie rock' 'auckland indie' 'australian americana'\n",
      " 'detroit indie' 'alternative americana' 'bristol indie'\n",
      " 'british singer-songwriter' 'indie anthem-folk' 'acoustic pop'\n",
      " 'indie cafe pop' 'cleveland indie' 'australian singer-songwriter'\n",
      " 'australian indie folk' 'folk-pop' 'acoustic punk' 'folk punk'\n",
      " 'heartland rock' 'chicago punk' 'melodic hardcore' 'new jersey indie'\n",
      " 'alternative country' 'gainesville indie' 'buffalo ny metal'\n",
      " 'boston metal' 'german metalcore' 'deathcore' 'groove metal'\n",
      " 'florida death metal' 'death metal' 'ccm' 'christian deathcore'\n",
      " 'comic metal' 'canadian metal' 'brutal deathcore' 'beatdown' 'hardcore'\n",
      " 'crossover thrash' 'boston hardcore' 'avant-garde metal' 'djent'\n",
      " 'deep melodic metalcore' 'canadian hardcore' 'cyberpunk'\n",
      " 'australian metal' 'omaha indie' 'asbury park indie' 'athens indie'\n",
      " 'midwest emo' 'anti-folk' 'la indie' 'alabama indie' 'bay area indie'\n",
      " 'stomp and holler' 'canadian indie' 'dream pop' 'lilith'\n",
      " 'adult standards' 'alternative dance' 'deep acoustic pop'\n",
      " 'alternative pop' 'gbvfi' 'ambient' 'british folk'\n",
      " 'american folk revival' 'art rock' 'canadian folk' 'minneapolis punk'\n",
      " 'canadian punk' 'screamo' 'pixie' 'australian metalcore'\n",
      " 'canadian metalcore' 'post-post-hardcore' 'italian metalcore'\n",
      " 'nu-metalcore' 'german post-hardcore' 'brutal death metal' 'black metal'\n",
      " 'atmospheric black metal' 'slam death metal' 'pornogrind'\n",
      " 'belarussian metal' 'belgian metal' 'neo mellow' 'bow pop' 'derby indie'\n",
      " 'diy emo' 'funk metal' 'comic' 'canadian pop punk' 'boy band'\n",
      " 'chicago hardcore' 'german punk' 'german rock' 'candy pop' 'punk'\n",
      " 'hardcore punk' 'oi' 'neo-proto' 'garage rock' 'chicano punk' 'ukhc'\n",
      " 'uk metalcore' 'bassline' 'australian hardcore'\n",
      " 'british alternative rock' 'german hardcore' 'australian post-hardcore'\n",
      " 'adelaide indie' 'uk post-hardcore' 'nz hardcore' 'britpop' 'irish rock'\n",
      " 'brighton indie' 'british indie rock' 'english indie rock'\n",
      " 'modern dream pop' 'australian alternative rock' 'australian hip hop'\n",
      " 'australian garage punk' 'cornwall indie' 'oxford indie' 'perth indie'\n",
      " 'metropopolis' 'finnish pop' 'german pop' 'finnish indie'\n",
      " 'finnish dance pop' 'electropop' 'gauze pop' 'europop'\n",
      " 'albuquerque indie' 'birmingham indie' 'glasgow indie'\n",
      " 'modern alternative rock' 'edinburgh indie' 'chamber psych'\n",
      " 'modern power pop' 'new rave' 'funk' 'blues rock' 'deep new americana'\n",
      " 'bath indie' 'alternative roots rock' 'garage punk blues'\n",
      " 'acoustic blues' 'escape room' 'canadian singer-songwriter'\n",
      " 'canadian pop' 'australian dance' 'alternative r&b' 'australian pop'\n",
      " 'bedroom pop' 'uk contemporary r&b' 'indie poptimism' 'pop'\n",
      " 'canadian contemporary r&b' 'deep pop edm' 'la pop' 'vapor pop'\n",
      " 'bass trap' 'arab trap' 'pop edm' 'rebel blues' 'nightcore' 'chicago rap'\n",
      " 'comedy rap' 'lgbtq+ hip hop' 'dmv rap' 'post-teen pop' 'disney'\n",
      " 'emo rap' 'trap soul' 'deep underground hip hop'\n",
      " 'australian alternative pop' 'indie r&b' 'social media pop'\n",
      " 'indie pop rap' 'indie electropop' 'edm' 'girl group' 'pop rap'\n",
      " 'viral pop' 'channel pop' 'bedroom soul' 'atlanta indie' 'chicago indie'\n",
      " 'austindie' 'indie garage rock' 'boston indie' 'hopebeat'\n",
      " 'american post-rock' 'compositional ambient' 'instrumental post-rock'\n",
      " 'british post-rock' 'alternative pop rock' 'canadian rock' 'pop emo'\n",
      " 'gothic alternative' 'melodic metal' 'connecticut hardcore'\n",
      " 'japanese emo' 'dutch indie rock' 'indie punk' 'american shoegaze'\n",
      " 'straight edge' 'modern hard rock' 'florida hardcore' 'fast melodic punk'\n",
      " 'brazilian hardcore' 'boston punk' 'skate punk' 'uk diy punk' 'ska punk'\n",
      " 'modern ska punk' 'texas punk' 'canadian celtic' 'nz punk' 'psychobilly'\n",
      " 'boston rock' 'orgcore' 'power-pop punk' 'pop rock' 'rochester mn indie'\n",
      " 'texas pop punk' 'swedish pop' 'australian electropop'\n",
      " 'deep tropical house' 'deep house' 'tropical house' 'new french touch'\n",
      " 'indie soul' 'vapor soul' 'opm' 'classic opm' 'filter house'\n",
      " 'aussietronica' 'dutch r&b' 'canadian electronic' 'scandipop'\n",
      " 'future garage' 'australian r&b' 'k-indie' 'thai indie pop'\n",
      " 'indonesian indie' 'thai indie rock' 'thai indie' 'indonesian folk'\n",
      " 'indonesian city pop' 'indonesian pop' 'indonesian jazz'\n",
      " 'classic indo pop' 'indonesian hip hop' 'k-hop' 'lo-fi beats'\n",
      " 'indonesian edm' 'electronic rock' 'industrial metal' 'future rock' 'ebm'\n",
      " 'new jersey hardcore' 'vegan straight edge' 'jazz metal' 'danish metal'\n",
      " 'post-screamo' 'manchester indie' 'progressive metalcore' 'glitch hop'\n",
      " 'jam band' 'glitch' 'electra' 'brostep' 'livetronica' 'shamanic'\n",
      " 'vapor twitch' 'belly dance' 'folktronica' 'electronic trap'\n",
      " 'experimental bass' 'jamtronica' 'funk rock' 'bluegrass' 'banjo'\n",
      " 'new orleans funk' 'afrobeat' 'jazz funk' 'instrumental funk'\n",
      " 'instrumental rock' 'chillhop' 'electro swing' 'australian reggae fusion'\n",
      " 'oriental classical' 'popping' 'french indie pop' 'catstep'\n",
      " 'funky breaks' 'bboy' 'big beat' 'breakbeat' 'deep psytrance'\n",
      " 'ambient psychill' 'nz electronic' 'neo-traditional bluegrass'\n",
      " 'roots americana' 'asheville indie' 'progressive bluegrass' 'jamgrass'\n",
      " 'indiecoustica' 'appalachian folk' 'classic rock' 'austin americana'\n",
      " 'columbus ohio indie' 'modern folk rock' 'arkansas indie'\n",
      " 'australian psych' 'freak folk' 'neo-psychedelic' 'garage pop'\n",
      " 'garage psych' 'canadian garage rock' 'art punk' 'calgary indie'\n",
      " 'action rock' 'experimental rock' 'noise pop' 'j-punk'\n",
      " 'experimental black metal' 'afrofuturism' 'bass music' 'chillwave'\n",
      " 'detroit hip hop' 'hip hop' 'dirty south rap' 'alternative hip hop'\n",
      " 'cali rap' 'conscious hip hop' 'atl hip hop' 'gangster rap' 'crunk'\n",
      " 'atl trap' 'soul flow' 'east coast hip hop' 'rap' 'chicago drill'\n",
      " 'canadian hip hop' 'deep pop r&b' 'underground hip hop' 'miami hip hop'\n",
      " 'nc hip hop' 'bronx hip hop' 'battle rap' 'hardcore hip hop' 'trap'\n",
      " 'alabama rap' 'g funk' 'boston hip hop' 'hip pop' 'grunge' 'riot grrrl'\n",
      " 'rock quebecois' 'dark cabaret' 'olympia wa indie' 'early us punk'\n",
      " 'queercore' 'melancholia' 'palm desert scene' 'instrumental stoner rock'\n",
      " 'modern blues rock' 'big room' 'complextro' 'bass house' 'electro house'\n",
      " 'deep melodic euro house' 'progressive house' 'house' 'chillstep'\n",
      " 'melodic dubstep' 'album rock' 'british invasion' 'acid rock'\n",
      " 'british blues' 'blues' 'experimental pop' 'e6fi' 'small room'\n",
      " 'quebec indie' 'victoria bc indie' 'swedish synth' 'dark electro'\n",
      " 'aggrotech' 'dark wave' 'full on' 'psychedelic trance' 'goa trance'\n",
      " 'forest psy' 'deep progressive trance' 'progressive psytrance'\n",
      " 'brazilian edm' 'didgeridoo' 'downtempo' 'psychill' 'progressive breaks'\n",
      " 'progressive uplifting trance' 'ukrainian electronic' 'eurodance'\n",
      " 'meme rap' 'ghanaian hip hop' 'minnesota hip hop' 'irish hip hop'\n",
      " 'uk alternative hip hop' 'london rap' 'dark trap' 'melodic rap'\n",
      " 'trap queen' 'deep dance pop' 'dancehall' 'barbadian pop' 'houston rap'\n",
      " 'canadian latin' 'british soul' 'bubblegum dance' 'bebop'\n",
      " 'avant-garde jazz' 'avant-garde' 'american modern classical'\n",
      " 'contemporary jazz' 'contemporary post-bop' 'jazz fusion' 'cool jazz'\n",
      " 'jazz guitar' 'french jazz' 'bmore' 'deep big room' 'deep groove house'\n",
      " 'norwegian pop' 'belgian edm' 'nyc pop' 'azonto' 'bongo flava' 'chutney'\n",
      " 'funana' 'reggae' 'lovers rock' 'modern reggae' 'afro dancehall'\n",
      " 'bhangra' 'hmong pop' 'romanian pop' 'dutch edm' 'disco house'\n",
      " 'indie singer-songwriter' 'swedish soul' 'swedish hip hop'\n",
      " 'swedish alternative rock' 'scandinavian r&b' 'swedish electropop'\n",
      " 'swedish gangsta rap' 'swedish americana' 'swedish indie pop'\n",
      " 'gothenburg hip hop' 'swedish idol pop' 'gothenburg indie'\n",
      " 'uk alternative pop' 'etherpop' 'dc indie' 'electronica' 'neo soul'\n",
      " 'grime' 'neo r&b' 'australian comedy' 'epicore' 'indietronica'\n",
      " 'shimmer pop']\n"
     ]
    }
   ],
   "source": [
    "#use this to check if there is a specific artist in the dataset\n",
    "print(\"The Black Keys\" in b[\"artist_name\"].values)\n",
    "\n",
    "#number of different artists\n",
    "unique_artists = b[\"artist_name\"].unique()\n",
    "print(\"Number of unique artists: \",len(unique_artists))\n",
    "\n",
    "#use this to see what different genres there are in the dataset\n",
    "unique_genres = b[\"genre\"].unique()\n",
    "#number of different genres\n",
    "print(\"Number of unique genres: \",len(unique_genres))\n",
    "#theres a lot so i just wanted to see the first 50\n",
    "print(unique_genres[ :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4929, 8)\n",
      "(2225, 8)\n",
      "(8439, 8)\n"
     ]
    }
   ],
   "source": [
    "#okay, now if we want to create separate dataframes of subsets, such as genre, or year, or artist, we can do so\n",
    "\n",
    "metalgenres = ['post-hardcore','metallic hardcore','metalcore','melodic metalcore','christian alternative rock',\n",
    "              'progressive post-hardcore', 'alternative metal','american metalcore','christian metal','christian hardcore',\n",
    "              'alabama metal','melodic hardcore' ,'deathcore', 'groove metal','death metal','christian deathcore','hardcore',\n",
    "              'beatdown','boston hardcore','djent','screamo' ,'swancore','post-post-hardcore','black metal','psychobilly', \n",
    "              'pornogrind','experimental black metal','danish metal']\n",
    "\n",
    "metal = b.loc[b['genre'].isin(metalgenres)]\n",
    "print(metal.shape)\n",
    "\n",
    "\n",
    "indiegenres = ['indie','pop punk','indie pop','mathcore','indie folk','indie rock','mathcore','canadian punk','modern alternative rock',\n",
    "              'indie garage rock','american post-rock','instrumental post-rock','pop emo','american shoegaze','texas pop punk',\n",
    "              'manchester indie','auckland indie','australian indie','detroit indie','indie anthem-folk','folk-pop',\n",
    "              'folk punk','midwest emo','bay area indie','canadian folk','canadian punk','diy emo','canadian pop punk',\n",
    "              'indie garage rock',]\n",
    "\n",
    "indie = b.loc[b['genre'].isin(indiegenres)]\n",
    "print(indie.shape)    \n",
    "\n",
    "\n",
    "trippygenres = ['indie pop','electropowerpop','art pop','cyberpunk','dream pop','alternative dance','ambient','neo mellow',\n",
    "               'modern dream pop','metropopolis','finnish dance pop','electropop','europop' ,'chamber psych','new rave',\n",
    "               'deep pop edm','vapor pop', 'bass trap','pop edm', 'edm','indie electropop','american shoegaze','deep house','deep tropical house',\n",
    "               'tropical house','filter house','aussietronica','lo-fi beats','glitch hop','glitch','shamanic','deep psytrance',\n",
    "               'electro house','deep melodic euro house','house','acid rock' ,'psychedelic trance','forest psy',\n",
    "               'deep progressive trance','progressive psytrance','psychill','dutch edm']\n",
    "\n",
    "trippy = b.loc[b['genre'].isin(trippygenres)]\n",
    "print(trippy.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#here we define a function that will iterate through your dataframe,\n",
    "#visit the images, and download those images to the folder specified\n",
    "#if the path to folder is not specified, it will create/download to a directory called \"albumartimages\"\n",
    "\n",
    "def getAndSaveAlbumArts(df, path = 'albumartimages/'):\n",
    "    isdir = os.path.isdir(path)\n",
    "    df = df[['link_to_image','album_name','artist_name']]\n",
    "    if isdir is not True:\n",
    "        os.mkdir(path)\n",
    "    for i, j in df.iterrows():\n",
    "        artistAlbumName = j[2]+ \"-\" + j[1]\n",
    "        artistAlbumName = artistAlbumName[:200] if len(artistAlbumName) > 200 else artistAlbumName\n",
    "        fileName = artistAlbumName + \".jpg\"\n",
    "        fileName = fileName.replace(r'/', ' ')\n",
    "        url = j[0]\n",
    "        r = requests.get(url)\n",
    "        fullPath = path + fileName\n",
    "        with open(fullPath, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    print(\"done\")\n",
    "\n",
    "    \n",
    "getAndSaveAlbumArts(trippy, path = 'trippy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is a function to resize the images after been downloaded into a directory.\n",
    "Coming from Spotify, most images are 640x640, but for our GAN, we want them to \n",
    "be a bit more manageable in size so we'll resize them to 128x128\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "src = \"trippy/\"\n",
    "dst = \"trippy_resized/\"\n",
    "dirs = os.listdir( src )\n",
    "\n",
    "\n",
    "def resize():\n",
    "    if os.path.isdir(dst) is not True:\n",
    "        os.mkdir(dst)\n",
    "    i=0\n",
    "    for item in dirs:\n",
    "        if (os.path.isfile(src+item) and item != \".DS_Store\"):\n",
    "            im = Image.open(src+item)\n",
    "            f, e = os.path.splitext(src+item)\n",
    "            imResize = im.resize((128,128), Image.ANTIALIAS)\n",
    "            output_file_name = os.path.join(dst, str(i) + \".jpeg\")\n",
    "            imResize.save(output_file_name, 'JPEG', quality=90)\n",
    "            i+=1\n",
    "\n",
    "#resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Once the images are resized, they all need to be normalized \n",
    "and then they can be saved to a pickle file or a python object \n",
    "so they can be read in easier than going through image by image\n",
    "in a directory\"\"\"\n",
    "#https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def normalize_images():\n",
    "    IMAGE_SIZE = 128\n",
    "    IMAGE_CHANNELS = 3\n",
    "    IMAGE_DIR = 'resized_imgs/'\n",
    "    \n",
    "    images_path = IMAGE_DIR \n",
    "\n",
    "    #create an empty array all the images will go into\n",
    "    training_data = []\n",
    "    \n",
    "    for filename in os.listdir(images_path):\n",
    "        path = os.path.join(images_path, filename)\n",
    "        #only need this if the image is not the right dimensions, but we're pulling from the already resized folder\n",
    "        image = Image.open(path).resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "        image = (image / 127.5) - 1\n",
    "        training_data.append(np.asarray(image))\n",
    "    \n",
    "    #reshape the whole array\n",
    "    training_data = np.reshape(training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "    #training_data = training_data / 127.5-1\n",
    "    np.savez_compressed('images_normalized.npy', training_data)\n",
    "    \n",
    "#normalize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4\n",
    "\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Preview image Frame\n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 4\n",
    "SAVE_FREQ = 100\n",
    "# Size vector to generate images from\n",
    "NOISE_SIZE = 100\n",
    "# Configuration\n",
    "EPOCHS = 10000 # number of iterations\n",
    "BATCH_SIZE = 32\n",
    "GENERATE_RES = 3\n",
    "IMAGE_SIZE = 128 # rows/cols\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "training_data = np.load('images_normalized.npy')\n",
    "#training_data = np.load(os.path.join(‘dirname’, ‘filename.npy’))\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2,\n",
    "    input_shape=image_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    return Model(input_image, validity)\n",
    "\n",
    "\n",
    "def build_generator(noise_size, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4 * 4 * 256, activation='relu', input_dim=noise_size))\n",
    "    model.add(Reshape((4, 4, 256)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(“relu”))\n",
    "    for i in range(GENERATE_RES):\n",
    "         model.add(UpSampling2D())\n",
    "         model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "         model.add(BatchNormalization(momentum=0.8))\n",
    "         model.add(Activation('relu'))\n",
    "    model.summary()\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=”same”))\n",
    "    model.add(Activation(“tanh”))\n",
    "    input = Input(shape=(noise_size,))\n",
    "    generated_image = model(input)\n",
    "    \n",
    "    return Model(input, generated_image)\n",
    "\n",
    "\n",
    "def save_images(cnt, noise):\n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c +\n",
    "                        IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "    output_path = 'output'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n",
    "    \n",
    "    \n",
    "\n",
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "optimizer = Adam(1.5e-4, 0.5)\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss=”binary_crossentropy”,\n",
    "optimizer=optimizer, metrics=[“accuracy”])\n",
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "random_input = Input(shape=(NOISE_SIZE,))\n",
    "generated_image = generator(random_input)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(generated_image)\n",
    "combined = Model(random_input, validity)\n",
    "combined.compile(loss=”binary_crossentropy”,\n",
    "optimizer=optimizer, metrics=[“accuracy”])\n",
    "y_real = np.ones((BATCH_SIZE, 1))\n",
    "y_fake = np.zeros((BATCH_SIZE, 1))\n",
    "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    " idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\n",
    " x_real = training_data[idx]\n",
    " \n",
    " noise= np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))\n",
    " x_fake = generator.predict(noise)\n",
    " \n",
    " discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)\n",
    "discriminator_metric_generated = discriminator.train_on_batch(\n",
    " x_fake, y_fake)\n",
    " \n",
    "discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)\n",
    "generator_metric = combined.train_on_batch(noise, y_real)\n",
    "if epoch % SAVE_FREQ == 0:\n",
    "   save_images(cnt, fixed_noise)\n",
    "   cnt += 1\n",
    " \n",
    "   print(f”{epoch} epoch, Discriminator accuracy: {100*  discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}”)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
