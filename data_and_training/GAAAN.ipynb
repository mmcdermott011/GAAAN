{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Album_Art_GAN.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdH5PNLmd8m2",
    "colab_type": "text"
   },
   "source": [
    "<h1>Generative Album Art Adversarial Network (GAAAN)</h1>\n",
    "This dcgan is an album art generator, adapted from the following articles\n",
    "https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4 \n",
    "\n",
    "https://colab.research.google.com/drive/1Mxbfn0BUW4BlgEPc-minaE_M0_PaYIIX#scrollTo=6AIl-8kWThY8\n",
    "\n",
    "Read more about this project here: https://github.com/mmcdermott011/GAAAN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0o260rnftHPH",
    "colab_type": "code",
    "outputId": "3a73d70d-f32a-4625-e7d0-83d34bfc80ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A_c35HezeAkq",
    "colab_type": "code",
    "outputId": "bcec9eda-b8fe-4549-a655-979dd45bc9c1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "%cd \"/content/drive/My Drive/Deep_Learning_Project\"\n",
    "!ls\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Deep_Learning_Project\n",
      "logs\t       metal_resized.zip  resized_imgs\t    saved_models\n",
      "metal_resized  output\t\t  resized_imgs.zip\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FuYhzHWeeChw",
    "colab_type": "code",
    "outputId": "b288a1ff-1434-4223-8e74-0df503f02b34",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, gridspec\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# Generation resolution - Must be square\n",
    "# Training data is also scaled to this.\n",
    "# Note GENERATE_RES 4 or higher  will blow Google CoLab's memory and have not\n",
    "# been tested extensively.\n",
    "from PIL import Image\n",
    "from keras import Sequential, Input, Model\n",
    "from keras.layers import Dense, Conv2D, LeakyReLU, Dropout, ZeroPadding2D, BatchNormalization, Flatten, Activation, \\\n",
    "    UpSampling2D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import model_to_dot\n",
    "import glob\n",
    "from keras import backend as K\n",
    "from keras.utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "\n",
    "# Preview image\n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 4\n",
    "PREVIEW_MARGIN = 16\n",
    "SAVE_FREQ = 500\n",
    "# Size vector to generate images from\n",
    "NOISE_SIZE = 100\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "IMAGE_DIR = 'metal_resized/*.jp*'\n",
    "images_path = IMAGE_DIR\n",
    "LOG_DIR = 'logs/'\n",
    "SAVE_MODEL_DIR = 'saved_models/'\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 50000 # number of iterations\n",
    "BATCH_SIZE = 64\n",
    "GENERATE_RES = 3 # Generation resolution factor (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "IMAGE_SIZE = 128 # rows/cols\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "GENERATE_SQUARE = 128 # rows/cols (should be square)\n",
    "\n",
    "disc_model = 'disc.hdf5' \n",
    "gen_model = 'gen.hdf5'\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ak7U4LCGea97",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# A function to normalize image pixels.\n",
    "def norm_img(img):\n",
    "    '''A function to Normalize Images.\n",
    "    Input:\n",
    "        img : Original image as numpy array.\n",
    "    Output: Normailized Image as numpy array\n",
    "    '''\n",
    "    img = (img / 127.5) - 1\n",
    "    return img\n",
    "\n",
    "def denorm_img(img):\n",
    "    '''A function to Denormailze, i.e. recreate image from normalized image\n",
    "    Input:\n",
    "        img : Normalized image as numpy array.\n",
    "    Output: Original Image as numpy array\n",
    "    '''\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def sample_from_dataset(batch_size, data_dir=None):\n",
    "    '''Create a batch of image samples by sampling random images from a data directory.\n",
    "    Assumes images are already the correct size, and will normalize the images.\n",
    "    Input:\n",
    "        batch_size : Sample size required\n",
    "        data_dir : Path of directory where training images are placed.\n",
    "\n",
    "    Output:\n",
    "        sample : batch of processed images\n",
    "    '''\n",
    "    sample_dim = (batch_size,) + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    all_data_dirlist = list(glob.glob(data_dir))\n",
    "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size)\n",
    "    for index,img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "        image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample\n",
    "\n",
    "def gen_noise(batch_size, noise_shape):\n",
    "    ''' Generates a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)\n",
    "    Input:\n",
    "        batch_size : size of batch\n",
    "        noise_shape: shape of noise vector, normally kept as 100\n",
    "    Output:a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)\n",
    "    '''\n",
    "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)\n",
    "\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=4, strides=2, input_shape=image_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    dis_opt = Adam(lr=0.0015, beta_1=0.5)\n",
    "\n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    discriminator_model = Model(input = input_image, output = validity)\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
    "    discriminator_model.summary()\n",
    "    return discriminator_model\n",
    "\n",
    "\n",
    "def build_generator(noise_size, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8 * 8 * 512, activation=\"relu\", input_dim = noise_size))\n",
    "    model.add(Reshape((8, 8, 512)))\n",
    "    model.add(UpSampling2D())\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=4, strides = 1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=4,strides = 1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=4, strides =1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(channels, kernel_size=4, strides = 1, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.summary()\n",
    "    gen_input = Input(shape=(noise_size,))\n",
    "    generated_image = model(gen_input)\n",
    "    gen_opt = Adam(lr=0.003, beta_1=0.5)\n",
    "    generator = Model(input = gen_input, output = generated_image)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
    "    return generator\n",
    "\n",
    "\n",
    "def save_images(cnt, noise):\n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c +\n",
    "                        IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "    output_path = 'output'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n",
    "\n",
    "\n",
    "\n",
    "def save_img_batch(img_batch,img_save_dir):\n",
    "    '''Takes as input a image batch and a img_save_dir and saves 16 images from the batch in a 4x4 grid in the img_save_dir\n",
    "    '''\n",
    "    plt.figure(figsize=(16,16))\n",
    "    gs1 = gridspec.GridSpec(4, 4)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    rand_indices = np.random.choice(img_batch.shape[0],16,replace=False)\n",
    "    for i in range(16):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        rand_index = rand_indices[i]\n",
    "        image = img_batch[rand_index, :,:,:]\n",
    "        fig = plt.imshow(denorm_img(image))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_save_dir,bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "import imageio\n",
    "img_save_dir = 'output/'\n",
    "generated_images = [img_save_dir+'trained-'+str(x)+\".png\" for x in range(1,74)]\n",
    "def make_gif():\n",
    "    images = []\n",
    "    for filename in generated_images:\n",
    "        images.append(imageio.imread(filename))\n",
    "\n",
    "    imageio.mimsave(img_save_dir + 'metal_v3.5.gif', images)\n",
    "\n",
    "#make_gif()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g79TGtZ5eivE",
    "colab_type": "code",
    "outputId": "4cf46446-ad51-4fb8-dfbb-900df227d149",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "#iscriminator = load_model(disc_model)\n",
    "#generator = load_model(gen_model)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "optimizer = Adam(1.5e-3, 0.5)\n",
    "\n",
    "gen_inp = Input(shape=(NOISE_SIZE,))\n",
    "GAN_inp = generator(gen_inp)\n",
    "GAN_opt = discriminator(GAN_inp)\n",
    "\n",
    "gan = Model(gen_inp, GAN_opt)\n",
    "gan.compile(loss=\"binary_crossentropy\",optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "gan.summary()\n",
    "\n",
    "\n",
    "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "\n",
    "\n",
    "#plot_model(generator, to_file='generator.png')\n",
    "#plot_model(discriminator, to_file='discriminator.png')\n",
    "avg_disc_fake_loss = []\n",
    "avg_disc_real_loss = []\n",
    "avg_GAN_loss = []\n",
    "\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    if(epoch%10 == 0):\n",
    "      print(\"EPOCH: \" + str(epoch))\n",
    "    #idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\n",
    "    #x_real = training_data[idx]\n",
    "    x_real = sample_from_dataset(BATCH_SIZE, data_dir=IMAGE_DIR)\n",
    "\n",
    "\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))\n",
    "    x_fake = generator.predict(noise)\n",
    "\n",
    "    y_real = np.ones((BATCH_SIZE, 1)) - np.random.random_sample(BATCH_SIZE) * 0.2\n",
    "    y_fake = np.random.random_sample(BATCH_SIZE) * 0.2\n",
    "\n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "\n",
    "    discriminator_metric_real = discriminator.train_on_batch(x_real, y_real[0])\n",
    "    discriminator_metric_generated = discriminator.train_on_batch(x_fake, y_fake)\n",
    "\n",
    "    avg_disc_fake_loss.append(discriminator_metric_real[0])\n",
    "    avg_disc_real_loss.append(discriminator_metric_generated[0])\n",
    "\n",
    "    generator.trainable = True\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)\n",
    "    generator_metric = gan.train_on_batch(noise, y_real[0])\n",
    "    generator_metric = gan.train_on_batch(noise, y_real[0])\n",
    "    avg_GAN_loss.append(generator_metric[0])\n",
    "\n",
    "\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        save_images(cnt, fixed_noise)\n",
    "        cnt += 1\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        #print(f\"{epoch} epoch, Discriminator accuracy: {100 * discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}\")\n",
    "        print(\"Average Disc_fake loss: %f\" % (np.mean(avg_disc_fake_loss)))\n",
    "        print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss)))\n",
    "        print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = False\n",
    "        # predict on fixed_noise\n",
    "        generator.save(SAVE_MODEL_DIR+str(cnt)+\"_TRIP_GEN.hdf5\")\n",
    "        discriminator.save(SAVE_MODEL_DIR+str(cnt)+\"_TRIP_DISC.hdf5\")\n",
    "        if epoch > 1:\n",
    "          disc_real_loss = np.array(avg_disc_real_loss)\n",
    "          disc_fake_loss = np.array(avg_disc_fake_loss)\n",
    "          GAN_loss = np.array(avg_GAN_loss)\n",
    "          # Plot the losses vs training steps\n",
    "          plt.figure(figsize=(16,8))\n",
    "          plt.plot(range(0,epoch+1), disc_real_loss, label=\"Discriminator Loss - Real\")\n",
    "          plt.plot(range(0,epoch+1), disc_fake_loss, label=\"Discriminator Loss - Fake\")\n",
    "          plt.plot(range(0,epoch+1), GAN_loss, label=\"Generator Loss\")\n",
    "          plt.xlabel('Steps')\n",
    "          plt.ylabel('Loss')\n",
    "          plt.legend()\n",
    "          plt.title('GAN Loss')\n",
    "          plt.grid(True)\n",
    "          plt.savefig('logs/losses_fig.png') \n",
    "          plt.show()\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2804449   \n",
      "=================================================================\n",
      "Total params: 2,804,449\n",
      "Trainable params: 2,802,529\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32768)             3309568   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 256)       2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 128)       524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 3)       6147      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 10,135,939\n",
      "Trainable params: 10,134,147\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:115: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 128, 128, 3)       10135939  \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 2804449   \n",
      "=================================================================\n",
      "Total params: 12,940,388\n",
      "Trainable params: 10,134,147\n",
      "Non-trainable params: 2,806,241\n",
      "_________________________________________________________________\n",
      "EPOCH: 0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-31c224bdbe39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#x_real = training_data[idx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mx_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-41590cac43c4>\u001b[0m in \u001b[0;36msample_from_dataset\u001b[0;34m(batch_size, data_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msample_imgs_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_dirlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_imgs_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZTAONAlagYXI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}